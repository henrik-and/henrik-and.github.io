<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>GUM Demo - File Source Extension</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        /* Custom range slider styling for a polished look */
        input[type=range] {
            -webkit-appearance: none;
            width: 100%;
            background: transparent;
        }
        input[type=range]::-webkit-slider-thumb {
            -webkit-appearance: none;
            height: 16px;
            width: 16px;
            border-radius: 50%;
            background: #4F46E5;
            cursor: pointer;
            margin-top: -6px;
        }
        input[type=range]::-webkit-slider-runnable-track {
            width: 100%;
            height: 4px;
            cursor: pointer;
            background: #E5E7EB;
            border-radius: 2px;
        }
    </style>
</head>
<body class="bg-gray-50 text-gray-800 font-sans p-8">

    <div class="max-w-3xl mx-auto bg-white rounded-xl shadow-sm border border-gray-200 overflow-hidden">
        
        <!-- Header -->
        <div class="p-6 border-b border-gray-100">
            <h1 class="text-2xl font-bold text-gray-900">Audio Source Selection Demo</h1>
            <p class="text-sm text-gray-500 mt-1">Proof of concept for injecting file streams into GUM workflows.</p>
        </div>

        <div class="p-6 space-y-8">
            
            <!-- Source Selector / Toggle -->
            <div>
                <label class="block text-xs font-semibold text-gray-400 uppercase tracking-wider mb-3">Input Source</label>
                <div class="flex bg-gray-100 p-1 rounded-lg w-fit">
                    <button id="btn-mode-mic" class="px-4 py-2 text-sm font-medium rounded-md shadow-sm bg-white text-gray-900 transition-all" onclick="setMode('mic')">
                        Microphone
                    </button>
                    <button id="btn-mode-file" class="px-4 py-2 text-sm font-medium rounded-md text-gray-500 hover:text-gray-900 transition-all" onclick="setMode('file')">
                        Audio File
                    </button>
                </div>
            </div>

            <!-- Contextual Settings Area -->
            <div class="bg-gray-50 rounded-lg border border-gray-200 p-5 transition-all duration-300">
                
                <!-- Mic UI -->
                <div id="ui-mic" class="block">
                    <div class="flex flex-col space-y-3">
                        <label class="text-sm font-medium text-gray-700">Select Input Device</label>
                        <select id="mic-select" class="block w-full pl-3 pr-10 py-2 text-base border-gray-300 focus:outline-none focus:ring-indigo-500 focus:border-indigo-500 sm:text-sm rounded-md border">
                            <option>Default Microphone</option>
                            <!-- Populated via JS -->
                        </select>
                        <p class="text-xs text-gray-500">Standard behavior: requests <code>getUserMedia</code> from selected device.</p>
                    </div>
                </div>

                <!-- File UI -->
                <div id="ui-file" class="hidden">
                    <div class="flex flex-col space-y-4">
                        
                        <!-- Local File Upload (New) -->
                        <div class="p-4 bg-indigo-50 border border-indigo-100 rounded-md">
                            <label class="block text-sm font-medium text-indigo-900 mb-2">Option A: Upload Local File</label>
                            <input type="file" id="local-file-input" accept="audio/*" class="block w-full text-sm text-gray-500
                                file:mr-4 file:py-2 file:px-4
                                file:rounded-full file:border-0
                                file:text-sm file:font-semibold
                                file:bg-indigo-100 file:text-indigo-700
                                hover:file:bg-indigo-200
                            "/>
                            <p class="text-xs text-indigo-700 mt-2">Browse your local <code>audio/</code> folder to test specific WAV files.</p>
                        </div>

                        <div class="relative flex py-2 items-center">
                            <div class="flex-grow border-t border-gray-200"></div>
                            <span class="flex-shrink-0 mx-4 text-gray-400 text-xs uppercase">Or use Preset</span>
                            <div class="flex-grow border-t border-gray-200"></div>
                        </div>

                        <!-- Preset Selection -->
                        <div class="opacity-75 hover:opacity-100 transition-opacity">
                            <label class="text-sm font-medium text-gray-700">Option B: Select Remote Preset</label>
                            <select id="file-select" class="mt-1 block w-full pl-3 pr-10 py-2 text-base border-gray-300 focus:outline-none focus:ring-indigo-500 focus:border-indigo-500 sm:text-sm rounded-md border">
                                <option value="https://actions.google.com/sounds/v1/alarms/beep_short.ogg">Short Beep (Remote Test)</option>
                                <option value="https://actions.google.com/sounds/v1/ambiences/coffee_shop.ogg">Coffee Shop Ambience</option>
                            </select>
                        </div>

                        <!-- Player Controls (Specific to File Mode) -->
                        <div class="flex items-center space-x-4 bg-white p-3 rounded border border-gray-200 mt-4">
                            <button id="file-play-btn" class="text-indigo-600 hover:text-indigo-800" onclick="togglePlay()">
                                <svg xmlns="http://www.w3.org/2000/svg" class="h-8 w-8" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M14.752 11.168l-3.197-2.132A1 1 0 0010 9.87v4.263a1 1 0 001.555.832l3.197-2.132a1 1 0 000-1.664z" />
                                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M21 12a9 9 0 11-18 0 9 9 0 0118 0z" />
                                </svg>
                            </button>
                            <div class="flex-1">
                                <div class="text-xs text-gray-400 mb-1 flex justify-between">
                                    <span>Playback Progress</span>
                                    <span id="file-time">0:00</span>
                                </div>
                                <div class="h-1 w-full bg-gray-100 rounded overflow-hidden">
                                    <div id="file-progress" class="h-full bg-indigo-500 w-0 transition-all duration-200"></div>
                                </div>
                            </div>
                            <label class="flex items-center space-x-2 cursor-pointer">
                                <input type="checkbox" id="file-loop" class="rounded text-indigo-600 focus:ring-indigo-500" checked>
                                <span class="text-sm text-gray-600">Loop</span>
                            </label>
                        </div>

                        <p class="text-xs text-gray-500">
                            <span class="font-bold text-amber-600">Note:</span> Uses <code>audioElement.captureStream()</code> to mock a MediaStream.
                        </p>
                    </div>
                </div>

            </div>

            <!-- Visualization / Output Area -->
            <div>
                <div class="flex justify-between items-end mb-2">
                    <label class="text-xs font-semibold text-gray-400 uppercase tracking-wider">Stream Output</label>
                    <span id="stream-status" class="text-xs px-2 py-1 rounded bg-gray-100 text-gray-500">Inactive</span>
                </div>
                
                <div class="relative h-32 bg-gray-900 rounded-lg overflow-hidden shadow-inner flex items-center justify-center">
                    <canvas id="visualizer" class="absolute inset-0 w-full h-full"></canvas>
                    <div id="start-overlay" class="absolute inset-0 bg-black/50 flex items-center justify-center z-10 backdrop-blur-sm">
                        <button id="btn-start" class="px-6 py-3 bg-indigo-600 hover:bg-indigo-700 text-white font-medium rounded-lg shadow transition-transform transform active:scale-95">
                            Start Capture
                        </button>
                    </div>
                </div>
            </div>

        </div>
    </div>

    <!-- Hidden audio element for the file source strategy -->
    <audio id="source-audio" crossorigin="anonymous"></audio>

<script>
/**
 * Application State
 */
const state = {
    mode: 'mic', // 'mic' | 'file'
    activeStream: null,
    audioContext: null,
    analyser: null,
    rafId: null,
    currentSourceUrl: null // Tracks current source to avoid re-loading same file
};

// DOM Elements
const els = {
    micUi: document.getElementById('ui-mic'),
    fileUi: document.getElementById('ui-file'),
    btnMic: document.getElementById('btn-mode-mic'),
    btnFile: document.getElementById('btn-mode-file'),
    audioElement: document.getElementById('source-audio'),
    fileSelect: document.getElementById('file-select'),
    fileInput: document.getElementById('local-file-input'),
    btnStart: document.getElementById('btn-start'),
    startOverlay: document.getElementById('start-overlay'),
    statusBadge: document.getElementById('stream-status'),
    canvas: document.getElementById('visualizer'),
    progressBar: document.getElementById('file-progress'),
    timeDisplay: document.getElementById('file-time'),
    loopCheck: document.getElementById('file-loop')
};

/**
 * UI Logic: Switching Modes
 */
function setMode(mode) {
    state.mode = mode;
    
    // Toggle UI visibility
    if (mode === 'mic') {
        els.micUi.classList.remove('hidden');
        els.fileUi.classList.add('hidden');
        
        // Tab styling
        els.btnMic.classList.add('bg-white', 'text-gray-900', 'shadow-sm');
        els.btnMic.classList.remove('text-gray-500', 'hover:text-gray-900');
        els.btnFile.classList.remove('bg-white', 'text-gray-900', 'shadow-sm');
        els.btnFile.classList.add('text-gray-500', 'hover:text-gray-900');
        
        // Pause audio if switching away
        els.audioElement.pause();
    } else {
        els.micUi.classList.add('hidden');
        els.fileUi.classList.remove('hidden');

        // Tab styling
        els.btnFile.classList.add('bg-white', 'text-gray-900', 'shadow-sm');
        els.btnFile.classList.remove('text-gray-500', 'hover:text-gray-900');
        els.btnMic.classList.remove('bg-white', 'text-gray-900', 'shadow-sm');
        els.btnMic.classList.add('text-gray-500', 'hover:text-gray-900');
    }

    // If we already started, restart the stream with the new mode
    if (state.activeStream) {
        startStream(); 
    }
}

/**
 * Helper: Toggle Play Manually
 */
function togglePlay() {
    if(els.audioElement.paused) {
        els.audioElement.play();
    } else {
        els.audioElement.pause();
    }
}

/**
 * Core Logic: Stream Acquisition
 */
async function getStream() {
    if (state.mode === 'mic') {
        // Standard GUM behavior
        const constraints = { audio: true, video: false };
        return navigator.mediaDevices.getUserMedia(constraints);
    } 
    else if (state.mode === 'file') {
        // File Source behavior
        // If the URL hasn't been set by an event listener yet, default to dropdown value
        if (!state.currentSourceUrl) {
             state.currentSourceUrl = els.fileSelect.value;
        }

        els.audioElement.src = state.currentSourceUrl;
        els.audioElement.loop = els.loopCheck.checked;
        
        try {
            await els.audioElement.play();
        } catch (e) {
            console.error("Autoplay blocked or failed", e);
            alert("Please interact with the page (click Play) to allow audio start.");
        }

        // The Magic: captureStream()
        // Note: mozCaptureStream for Firefox support
        const stream = els.audioElement.captureStream ? 
                       els.audioElement.captureStream() : 
                       els.audioElement.mozCaptureStream();
        
        return stream;
    }
}

/**
 * Stream Management
 */
async function startStream() {
    stopStream(); // Cleanup existing

    try {
        els.statusBadge.innerText = "Acquiring...";
        els.statusBadge.className = "text-xs px-2 py-1 rounded bg-yellow-100 text-yellow-800";

        const stream = await getStream();
        state.activeStream = stream;

        // Visual feedback
        els.statusBadge.innerText = state.mode === 'mic' ? "ðŸ”´ Live Mic" : "ðŸ’¾ File Stream";
        els.statusBadge.className = "text-xs px-2 py-1 rounded bg-green-100 text-green-800";
        els.startOverlay.classList.add('hidden');

        // Connect to visualizer
        visualize(stream);

    } catch (err) {
        console.error("Error getting stream:", err);
        els.statusBadge.innerText = "Error";
        els.statusBadge.className = "text-xs px-2 py-1 rounded bg-red-100 text-red-800";
    }
}

function stopStream() {
    if (state.activeStream) {
        state.activeStream.getTracks().forEach(track => track.stop());
    }
    if (state.audioContext) {
        state.audioContext.close();
        state.audioContext = null;
    }
    if (state.rafId) {
        cancelAnimationFrame(state.rafId);
    }
}

/**
 * Visualizer Logic (To prove data is flowing)
 */
function visualize(stream) {
    state.audioContext = new (window.AudioContext || window.webkitAudioContext)();
    const source = state.audioContext.createMediaStreamSource(stream);
    state.analyser = state.audioContext.createAnalyser();
    
    state.analyser.fftSize = 256;
    source.connect(state.analyser);
    
    // Optional: Connect to destination so we can hear the file we are playing
    if (state.mode === 'file') {
        source.connect(state.audioContext.destination);
    }

    const bufferLength = state.analyser.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);
    const canvas = els.canvas;
    const ctx = canvas.getContext('2d');

    // Resize handling
    canvas.width = canvas.parentElement.offsetWidth;
    canvas.height = canvas.parentElement.offsetHeight;

    function draw() {
        state.rafId = requestAnimationFrame(draw);
        state.analyser.getByteFrequencyData(dataArray);

        ctx.fillStyle = '#111827'; // Dark bg
        ctx.fillRect(0, 0, canvas.width, canvas.height);

        const barWidth = (canvas.width / bufferLength) * 2.5;
        let barHeight;
        let x = 0;

        for(let i = 0; i < bufferLength; i++) {
            barHeight = dataArray[i] / 2;
            
            // Dynamic color based on height
            const r = barHeight + (25 * (i/bufferLength));
            const g = 250 * (i/bufferLength);
            const b = 50;

            ctx.fillStyle = `rgb(${r},${g},${b})`;
            ctx.fillRect(x, canvas.height - barHeight, barWidth, barHeight);

            x += barWidth + 1;
        }
    }
    draw();
}

/**
 * Event Listeners
 */
els.btnStart.addEventListener('click', startStream);

// Audio Element Events (File Mode UX)
els.audioElement.addEventListener('timeupdate', () => {
    if(els.audioElement.duration) {
        const pct = (els.audioElement.currentTime / els.audioElement.duration) * 100;
        els.progressBar.style.width = `${pct}%`;
        
        const mins = Math.floor(els.audioElement.currentTime / 60);
        const secs = Math.floor(els.audioElement.currentTime % 60);
        els.timeDisplay.innerText = `${mins}:${secs.toString().padStart(2, '0')}`;
    }
});

// Settings changes triggering restart
els.loopCheck.addEventListener('change', (e) => {
    els.audioElement.loop = e.target.checked;
});

// -- NEW: Handle Local File Upload --
els.fileInput.addEventListener('change', function() {
    if (this.files && this.files[0]) {
        state.currentSourceUrl = URL.createObjectURL(this.files[0]);
        // Auto-restart stream if we are in file mode to play the new file immediately
        if (state.mode === 'file' && state.activeStream) {
            startStream();
        }
    }
});

// -- Handle Preset Selection --
els.fileSelect.addEventListener('change', function() {
    state.currentSourceUrl = this.value;
    // Clear the file input visually so it's clear we are using the dropdown
    els.fileInput.value = ''; 
    
    if (state.mode === 'file' && state.activeStream) {
        startStream();
    }
});

</script>
</body>
</html>